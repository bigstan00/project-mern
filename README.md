# MERN Application Deployment with Auto-scaling

## Project Overview

### Project Name:
MERN Application Deployment with Auto-scaling

### Description:
This project involves the deployment of a MERN (MongoDB, Express, React, Node.js) stack application to AWS EC2 instances, with scalability features using Docker, Prometheus, Alertmanager, and auto-scaling scripts.

### Features:
- MERN stack setup
- Auto-scaling with AWS Lambda
- Prometheus monitoring and alerting with Alertmanager
- Frontend and Backend deployment on separate EC2 instances
- Docker Compose setup for local development and production environments

## Technologies Used
- **Frontend:** React, NGINX (for reverse proxy)
- **Backend:** Node.js, Express, MongoDB, NGINX
- **Deployment:** AWS EC2, Docker, Docker Compose
- **Monitoring and Alerting:** Prometheus, Alertmanager
- **CI/CD Tools:** GitHub Actions (or other CI/CD platforms)
- **Other Tools:** curl, stress-ng (for load testing)
- **Networking:** Netplan (used to make the IP static)
- **Nginx:** Reverse proxy for backend security

## Setup and Installation

### Prerequisites:
- AWS account for EC2 instances
- Docker and Docker Compose installed on the local machine
- MongoDB Atlas account (for remote MongoDB database)
- SSH key pair for EC2 instance access

### Cloning the Repository:

git clone https://github.com/bigstan00/project-mern.git
cd project-mern
Environment Setup:
Create a .env file in the root directory with the necessary environment variables:
bash
Copy code
DB_URL=mongodb+srv://your-username:your-password@cluster0.mongodb.net/
PORT=3500
Building the Docker Images:
From the project root directory, build the images for both frontend and backend:
bash
Copy code
docker-compose up --build
Starting Containers:
After building, start the containers:
bash
Copy code
docker-compose up -d
Project Structure
    • Root Directory:
        ◦ docker-compose.yaml: Configuration for Docker Compose to set up services like frontend, backend, Prometheus, Alertmanager, etc.
        ◦ .env: Contains environment variables such as database URL and port configuration.
        ◦ scale.sh: Auto-scaling script for the backend service.
        ◦ scale.log: Logs generated by the auto-scaling script.
        ◦ alert-rule.yaml: Prometheus alerting rules.
        ◦ prometheus.yaml: Prometheus configuration file.
    • Frontend Directory:
        ◦ Dockerfile: Dockerfile to set up the frontend container.
        ◦ src/: Source code for the React app.
        ◦ package.json and package-lock.json: Dependencies for the React frontend.
    • Backend Directory:
        ◦ Dockerfile: Dockerfile for backend service setup (Node.js, Express).
        ◦ index.js: Main entry point for the backend service.
        ◦ package.json and package-lock.json: Backend service dependencies.
Deployment
Frontend and Backend Deployment:
The frontend and backend are deployed using Docker containers to separate EC2 instances. The frontend service runs on port 3000, while the backend runs on port 3500 and is served through an NGINX reverse proxy.
Using CI/CD for Automated Deployment:
The CI pipeline automates the deployment of both frontend and backend to the respective EC2 instance. The pipeline also includes an auto-scaling script triggered based on certain conditions.
Auto-Scaling
scale.sh Script:
The scale.sh script automatically scales the backend service based on resource usage (CPU, memory).
Scaling Configuration:
When the system detects high resource usage, the script triggers AWS Lambda functions to launch new EC2 instances for the backend service.
Scaling Log:
Logs of scaling activities are stored in scale.log.
Monitoring and Alerts
Prometheus Setup:
Prometheus scrapes metrics from Node Exporter and the backend service. The Prometheus server is configured to collect these metrics at regular intervals.
Alertmanager:
Alertmanager handles alerts triggered by Prometheus when metrics exceed certain thresholds (e.g., high CPU usage or memory usage). Alerts are sent to the configured recipient via email.
Testing
Stress Testing the Backend:
You can stress test the backend using the stress-ng tool. Here are some examples:
bash
Copy code
stress-ng --cpu 4 --timeout 60s
stress-ng --vm 2 --vm-bytes 2G --timeout 60s
stress-ng --io 1 --timeout 60s
Health Checks:
Health checks are set up to ensure that both frontend and backend containers are running properly. If a container fails, Docker restarts it.
Troubleshooting
Backend Not Connecting to MongoDB:
If the backend is not connecting to MongoDB, it could be due to IP access restrictions in MongoDB Atlas. This issue was resolved by configuring a static IP on the local machine using netplan. The static IP ensures the backend is always using the same IP address, so it no longer requires frequent IP whitelisting in MongoDB Atlas.
Steps to resolve:
    1. Configure a static IP on your machine using netplan:
        ◦ Edit the netplan configuration file and set a static IP.
        ◦ Apply the changes and verify the static IP.
    2. Once the static IP is set, MongoDB Atlas will recognize the consistent IP, and the backend should connect without needing to update the IP whitelist regularly.
Deprecated Packages:
During the development of this application, it was noted that several dependencies are using deprecated packages. This may lead to potential security vulnerabilities, performance issues, or incompatibilities with newer versions of Node.js or other libraries.
Steps to mitigate:
    • Regularly update outdated dependencies.
    • Replace deprecated packages with actively maintained alternatives.
    • Use npm audit to identify vulnerabilities and outdated packages.
### Future Enhancements
    • Additional Auto-scaling Rules: Implement more advanced auto-scaling based on request load, not just CPU or memory usage.
    • Improved Monitoring: Integrate more detailed application-level monitoring with tools like Grafana.
    • Error Handling: Improve error handling and logging in both frontend and backend services.

### Conclusion
This project successfully deploys a scalable MERN application with monitoring, alerting, and auto-scaling features. It leverages Docker, AWS, and Prometheus to ensure the application remains performant even as traffic increases.
